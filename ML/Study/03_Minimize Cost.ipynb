{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cost를 최소화 하는 방법\n",
    "\n",
    "Gradient Descent algorithm(경사 하강 알고리즘)\n",
    "\n",
    "- Minimize cost Function\n",
    "- Gradient descent is used many minimization\n",
    "\n",
    "\n",
    "### how it works?\n",
    "- start with initial guesses\n",
    "- Each time you change the parameters, you select the gradient which reduces cost(W,b) the most possible\n",
    "- Repeat"
   ],
   "id": "327ff50538be8db1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hypothesis\n",
    "h(x) = Wx"
   ],
   "id": "fd4e536061202a04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:36:44.460233Z",
     "start_time": "2025-12-16T12:36:41.618961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), name = 'weights')\n",
    "b = tf.Variable(tf.random.normal([1]), name = 'bias')\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01)\n",
    "\n",
    "for step in range(1001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * x + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "    grad = tape.gradient(cost, [W,b])\n",
    "\n",
    "    optimizer.apply_gradients(zip(grad, [W,b]))\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost:\", cost.numpy(), \"W:\", W.numpy(), \"b:\", b.numpy())\n"
   ],
   "id": "a675672bcb1e5255",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 5.8966537 W: [0.59257066] b: [-1.3246524]\n",
      "10 Cost: 0.6753594 W: [1.1561404] b: [-1.0494978]\n",
      "20 Cost: 0.17283988 W: [1.3233416] b: [-0.9493544]\n",
      "30 Cost: 0.11988965 W: [1.3683923] b: [-0.90357745]\n",
      "40 Cost: 0.10998684 W: [1.3759061] b: [-0.8749303]\n",
      "50 Cost: 0.104411446 W: [1.3719885] b: [-0.8519146]\n",
      "60 Cost: 0.099465765 W: [1.364692] b: [-0.8309735]\n",
      "70 Cost: 0.09478757 W: [1.3564974] b: [-0.81100184]\n",
      "80 Cost: 0.09033251 W: [1.3481672] b: [-0.79165053]\n",
      "90 Cost: 0.08608717 W: [1.3399329] b: [-0.7728043]\n",
      "100 Cost: 0.08204142 W: [1.331863] b: [-0.75442016]\n",
      "110 Cost: 0.07818579 W: [1.3239754] b: [-0.7364775]\n",
      "120 Cost: 0.07451137 W: [1.3162723] b: [-0.71896285]\n",
      "130 Cost: 0.07100962 W: [1.3087515] b: [-0.70186514]\n",
      "140 Cost: 0.06767246 W: [1.3014092] b: [-0.6851741]\n",
      "150 Cost: 0.06449211 W: [1.2942415] b: [-0.66888005]\n",
      "160 Cost: 0.06146121 W: [1.2872442] b: [-0.6529735]\n",
      "170 Cost: 0.05857275 W: [1.2804133] b: [-0.63744515]\n",
      "180 Cost: 0.055820018 W: [1.2737447] b: [-0.6222861]\n",
      "190 Cost: 0.053196717 W: [1.2672348] b: [-0.60748756]\n",
      "200 Cost: 0.05069664 W: [1.2608798] b: [-0.59304094]\n",
      "210 Cost: 0.048314083 W: [1.2546757] b: [-0.5789379]\n",
      "220 Cost: 0.04604352 W: [1.2486193] b: [-0.5651702]\n",
      "230 Cost: 0.04387963 W: [1.2427069] b: [-0.55173]\n",
      "240 Cost: 0.041817456 W: [1.2369351] b: [-0.53860927]\n",
      "250 Cost: 0.0398522 W: [1.2313006] b: [-0.5258007]\n",
      "260 Cost: 0.0379793 W: [1.2258002] b: [-0.51329666]\n",
      "270 Cost: 0.036194403 W: [1.2204303] b: [-0.50109005]\n",
      "280 Cost: 0.034493428 W: [1.2151884] b: [-0.48917368]\n",
      "290 Cost: 0.032872375 W: [1.210071] b: [-0.47754067]\n",
      "300 Cost: 0.031327456 W: [1.2050754] b: [-0.46618432]\n",
      "310 Cost: 0.029855182 W: [1.2001983] b: [-0.455098]\n",
      "320 Cost: 0.028452111 W: [1.1954374] b: [-0.44427538]\n",
      "330 Cost: 0.027114958 W: [1.1907897] b: [-0.43371007]\n",
      "340 Cost: 0.02584066 W: [1.1862527] b: [-0.42339602]\n",
      "350 Cost: 0.024626248 W: [1.1818235] b: [-0.41332728]\n",
      "360 Cost: 0.023468897 W: [1.1774994] b: [-0.403498]\n",
      "370 Cost: 0.022365937 W: [1.1732782] b: [-0.39390242]\n",
      "380 Cost: 0.021314837 W: [1.1691576] b: [-0.38453504]\n",
      "390 Cost: 0.020313099 W: [1.165135] b: [-0.37539044]\n",
      "400 Cost: 0.019358492 W: [1.1612079] b: [-0.36646333]\n",
      "410 Cost: 0.018448679 W: [1.1573741] b: [-0.35774848]\n",
      "420 Cost: 0.017581671 W: [1.1536316] b: [-0.34924084]\n",
      "430 Cost: 0.016755374 W: [1.149978] b: [-0.34093553]\n",
      "440 Cost: 0.01596794 W: [1.1464114] b: [-0.33282775]\n",
      "450 Cost: 0.015217517 W: [1.1429299] b: [-0.32491285]\n",
      "460 Cost: 0.01450235 W: [1.1395307] b: [-0.3171861]\n",
      "470 Cost: 0.013820781 W: [1.1362126] b: [-0.3096431]\n",
      "480 Cost: 0.013171271 W: [1.1329733] b: [-0.3022795]\n",
      "490 Cost: 0.012552261 W: [1.129811] b: [-0.295091]\n",
      "500 Cost: 0.011962351 W: [1.126724] b: [-0.28807345]\n",
      "510 Cost: 0.011400166 W: [1.1237104] b: [-0.28122282]\n",
      "520 Cost: 0.010864385 W: [1.1207683] b: [-0.27453506]\n",
      "530 Cost: 0.010353809 W: [1.1178964] b: [-0.26800635]\n",
      "540 Cost: 0.009867221 W: [1.1150928] b: [-0.26163292]\n",
      "550 Cost: 0.009403486 W: [1.1123557] b: [-0.25541103]\n",
      "560 Cost: 0.008961556 W: [1.1096839] b: [-0.24933708]\n",
      "570 Cost: 0.008540397 W: [1.1070755] b: [-0.24340762]\n",
      "580 Cost: 0.008139022 W: [1.1045291] b: [-0.23761916]\n",
      "590 Cost: 0.007756525 W: [1.102043] b: [-0.23196831]\n",
      "600 Cost: 0.0073919906 W: [1.0996164] b: [-0.22645181]\n",
      "610 Cost: 0.0070445915 W: [1.0972475] b: [-0.22106653]\n",
      "620 Cost: 0.0067135226 W: [1.0949348] b: [-0.21580935]\n",
      "630 Cost: 0.0063980147 W: [1.0926772] b: [-0.21067716]\n",
      "640 Cost: 0.006097328 W: [1.0904733] b: [-0.20566708]\n",
      "650 Cost: 0.0058107823 W: [1.0883218] b: [-0.20077616]\n",
      "660 Cost: 0.0055376985 W: [1.0862215] b: [-0.19600153]\n",
      "670 Cost: 0.0052774376 W: [1.0841709] b: [-0.19134042]\n",
      "680 Cost: 0.005029421 W: [1.0821694] b: [-0.18679018]\n",
      "690 Cost: 0.004793065 W: [1.0802153] b: [-0.18234819]\n",
      "700 Cost: 0.0045677912 W: [1.0783076] b: [-0.17801176]\n",
      "710 Cost: 0.0043531307 W: [1.0764455] b: [-0.17377847]\n",
      "720 Cost: 0.004148553 W: [1.0746275] b: [-0.16964586]\n",
      "730 Cost: 0.003953583 W: [1.0728528] b: [-0.16561154]\n",
      "740 Cost: 0.0037677893 W: [1.0711201] b: [-0.16167314]\n",
      "750 Cost: 0.003590708 W: [1.0694289] b: [-0.15782838]\n",
      "760 Cost: 0.003421955 W: [1.0677779] b: [-0.15407504]\n",
      "770 Cost: 0.0032611291 W: [1.066166] b: [-0.150411]\n",
      "780 Cost: 0.0031078786 W: [1.0645926] b: [-0.1468341]\n",
      "790 Cost: 0.002961817 W: [1.0630565] b: [-0.14334229]\n",
      "800 Cost: 0.0028226303 W: [1.0615572] b: [-0.13993351]\n",
      "810 Cost: 0.0026899695 W: [1.0600929] b: [-0.13660577]\n",
      "820 Cost: 0.002563548 W: [1.058664] b: [-0.1333571]\n",
      "830 Cost: 0.0024430745 W: [1.0572689] b: [-0.1301857]\n",
      "840 Cost: 0.002328249 W: [1.0559069] b: [-0.12708972]\n",
      "850 Cost: 0.002218833 W: [1.0545774] b: [-0.12406737]\n",
      "860 Cost: 0.0021145598 W: [1.0532794] b: [-0.1211169]\n",
      "870 Cost: 0.0020151776 W: [1.0520124] b: [-0.11823659]\n",
      "880 Cost: 0.001920472 W: [1.0507756] b: [-0.11542481]\n",
      "890 Cost: 0.0018302171 W: [1.049568] b: [-0.1126799]\n",
      "900 Cost: 0.0017442087 W: [1.0483893] b: [-0.11000025]\n",
      "910 Cost: 0.0016622366 W: [1.0472386] b: [-0.10738436]\n",
      "920 Cost: 0.0015841139 W: [1.0461153] b: [-0.10483067]\n",
      "930 Cost: 0.0015096692 W: [1.0450186] b: [-0.1023377]\n",
      "940 Cost: 0.001438715 W: [1.0439479] b: [-0.09990402]\n",
      "950 Cost: 0.0013711011 W: [1.042903] b: [-0.09752821]\n",
      "960 Cost: 0.0013066634 W: [1.0418825] b: [-0.09520894]\n",
      "970 Cost: 0.0012452595 W: [1.0408865] b: [-0.09294476]\n",
      "980 Cost: 0.001186733 W: [1.039914] b: [-0.09073442]\n",
      "990 Cost: 0.0011309647 W: [1.038965] b: [-0.08857661]\n",
      "1000 Cost: 0.0010778122 W: [1.0380384] b: [-0.08647018]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "수동으로 Gradient 계산해서 W만 assign으로 갱신",
   "id": "ef5717617824f74f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:31:35.661822Z",
     "start_time": "2025-12-16T12:31:35.653676Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 19,
   "source": [
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * x - Y) * x)\n",
    "desecnt = W - learning_rate * gradient\n",
    "update = W.assign(desecnt)"
   ],
   "id": "22c97fcdfbc110ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "위 방식을 적용하면",
   "id": "5f051efdcd45316f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T13:14:26.392657Z",
     "start_time": "2025-12-16T13:14:25.267227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = tf.constant([1.,2.,3.])\n",
    "Y = tf.constant([1.,2.,3.])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), name = 'weights')\n",
    "b = tf.Variable(tf.random.normal([1]), name = 'bias')\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "for step in range(1001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * x + b\n",
    "\n",
    "        # MSE cost\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "        # (1/m) * sum((hypothesis - Y) * X)\n",
    "        grad_W = tf.reduce_mean((hypothesis - Y) * X)\n",
    "        grad_b = tf.reduce_mean(hypothesis - Y)\n",
    "\n",
    "        #  경사하강 업데이트\n",
    "        W.assign(W - learning_rate * grad_W)\n",
    "        b.assign(b - learning_rate * grad_b)\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(step, \"Cost:\", cost.numpy(), \"W:\", W.numpy(), \"b:\", b.numpy())\n"
   ],
   "id": "7fa5354de2cc6631",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 20.219976 W: [-0.34235123] b: [-1.4195923]\n",
      "10 Cost: 6.5042686 W: [0.3705609] b: [-1.0960693]\n",
      "20 Cost: 2.122097 W: [0.7719352] b: [-0.90971094]\n",
      "30 Cost: 0.7212801 W: [0.9972551] b: [-0.80091625]\n",
      "40 Cost: 0.27279675 W: [1.1230919] b: [-0.7360001]\n",
      "50 Cost: 0.1285341 W: [1.1927214] b: [-0.6959239]\n",
      "60 Cost: 0.08146959 W: [1.2306019] b: [-0.66992706]\n",
      "70 Cost: 0.06547562 W: [1.2505563] b: [-0.6519275]\n",
      "80 Cost: 0.059429202 W: [1.2603967] b: [-0.6384873]\n",
      "90 Cost: 0.05658245 W: [1.2645382] b: [-0.627663]\n",
      "100 Cost: 0.054779503 W: [1.2654756] b: [-0.61835575]\n",
      "110 Cost: 0.053331252 W: [1.264619] b: [-0.6099441]\n",
      "120 Cost: 0.052016985 W: [1.2627653] b: [-0.6020762]\n",
      "130 Cost: 0.050765753 W: [1.260364] b: [-0.59455276]\n",
      "140 Cost: 0.049554467 W: [1.25767] b: [-0.5872609]\n",
      "150 Cost: 0.048375193 W: [1.2548261] b: [-0.5801363]\n",
      "160 Cost: 0.047224987 W: [1.2519132] b: [-0.5731421]\n",
      "170 Cost: 0.046102434 W: [1.248977] b: [-0.56625706]\n",
      "180 Cost: 0.045006692 W: [1.2460432] b: [-0.5594688]\n",
      "190 Cost: 0.04393701 W: [1.2431258] b: [-0.55276984]\n",
      "200 Cost: 0.042892743 W: [1.240233] b: [-0.54615545]\n",
      "210 Cost: 0.041873336 W: [1.2373688] b: [-0.53962284]\n",
      "220 Cost: 0.040878136 W: [1.2345353] b: [-0.53316987]\n",
      "230 Cost: 0.0399066 W: [1.231734] b: [-0.52679485]\n",
      "240 Cost: 0.038958166 W: [1.228965] b: [-0.5204965]\n",
      "250 Cost: 0.038032234 W: [1.2262286] b: [-0.51427364]\n",
      "260 Cost: 0.037128307 W: [1.2235245] b: [-0.50812536]\n",
      "270 Cost: 0.036245894 W: [1.2208526] b: [-0.5020507]\n",
      "280 Cost: 0.035384465 W: [1.2182125] b: [-0.49604872]\n",
      "290 Cost: 0.034543503 W: [1.215604] b: [-0.49011853]\n",
      "300 Cost: 0.033722505 W: [1.2130265] b: [-0.48425925]\n",
      "310 Cost: 0.03292104 W: [1.2104799] b: [-0.47847003]\n",
      "320 Cost: 0.032138612 W: [1.2079636] b: [-0.47274995]\n",
      "330 Cost: 0.031374782 W: [1.2054775] b: [-0.4670983]\n",
      "340 Cost: 0.030629123 W: [1.203021] b: [-0.4615142]\n",
      "350 Cost: 0.02990117 W: [1.200594] b: [-0.4559969]\n",
      "360 Cost: 0.029190486 W: [1.1981958] b: [-0.45054546]\n",
      "370 Cost: 0.028496727 W: [1.1958264] b: [-0.4451593]\n",
      "380 Cost: 0.027819455 W: [1.1934853] b: [-0.43983746]\n",
      "390 Cost: 0.027158262 W: [1.1911721] b: [-0.43457928]\n",
      "400 Cost: 0.026512796 W: [1.1888866] b: [-0.429384]\n",
      "410 Cost: 0.025882682 W: [1.1866286] b: [-0.42425075]\n",
      "420 Cost: 0.02526752 W: [1.1843976] b: [-0.4191789]\n",
      "430 Cost: 0.024667008 W: [1.1821932] b: [-0.4141677]\n",
      "440 Cost: 0.024080766 W: [1.1800151] b: [-0.40921634]\n",
      "450 Cost: 0.023508416 W: [1.1778629] b: [-0.40432423]\n",
      "460 Cost: 0.022949724 W: [1.1757367] b: [-0.3994906]\n",
      "470 Cost: 0.022404261 W: [1.1736357] b: [-0.39471474]\n",
      "480 Cost: 0.021871805 W: [1.1715599] b: [-0.389996]\n",
      "490 Cost: 0.021351963 W: [1.169509] b: [-0.38533366]\n",
      "500 Cost: 0.020844499 W: [1.1674825] b: [-0.38072705]\n",
      "510 Cost: 0.02034908 W: [1.1654803] b: [-0.3761755]\n",
      "520 Cost: 0.019865455 W: [1.1635019] b: [-0.37167838]\n",
      "530 Cost: 0.019393299 W: [1.1615468] b: [-0.36723498]\n",
      "540 Cost: 0.018932372 W: [1.1596156] b: [-0.36284462]\n",
      "550 Cost: 0.018482408 W: [1.1577075] b: [-0.3585068]\n",
      "560 Cost: 0.018043144 W: [1.1558222] b: [-0.35422087]\n",
      "570 Cost: 0.017614303 W: [1.1539594] b: [-0.34998617]\n",
      "580 Cost: 0.01719567 W: [1.1521189] b: [-0.34580213]\n",
      "590 Cost: 0.016787002 W: [1.1503004] b: [-0.3416681]\n",
      "600 Cost: 0.01638803 W: [1.1485035] b: [-0.3375835]\n",
      "610 Cost: 0.01599853 W: [1.1467282] b: [-0.33354774]\n",
      "620 Cost: 0.01561829 W: [1.1449741] b: [-0.3295602]\n",
      "630 Cost: 0.015247089 W: [1.1432409] b: [-0.32562032]\n",
      "640 Cost: 0.014884715 W: [1.1415285] b: [-0.32172757]\n",
      "650 Cost: 0.014530957 W: [1.1398365] b: [-0.3178814]\n",
      "660 Cost: 0.01418561 W: [1.1381649] b: [-0.3140812]\n",
      "670 Cost: 0.013848464 W: [1.1365132] b: [-0.31032643]\n",
      "680 Cost: 0.013519331 W: [1.1348811] b: [-0.3066165]\n",
      "690 Cost: 0.01319801 W: [1.1332687] b: [-0.30295095]\n",
      "700 Cost: 0.012884326 W: [1.1316755] b: [-0.29932922]\n",
      "710 Cost: 0.012578131 W: [1.1301013] b: [-0.2957508]\n",
      "720 Cost: 0.0122791855 W: [1.128546] b: [-0.29221514]\n",
      "730 Cost: 0.011987354 W: [1.1270093] b: [-0.28872177]\n",
      "740 Cost: 0.011702463 W: [1.1254909] b: [-0.2852701]\n",
      "750 Cost: 0.011424329 W: [1.1239907] b: [-0.2818598]\n",
      "760 Cost: 0.011152794 W: [1.1225083] b: [-0.27849022]\n",
      "770 Cost: 0.010887738 W: [1.1210438] b: [-0.2751609]\n",
      "780 Cost: 0.010628956 W: [1.1195966] b: [-0.2718714]\n",
      "790 Cost: 0.01037635 W: [1.1181668] b: [-0.2686212]\n",
      "800 Cost: 0.010129737 W: [1.1167542] b: [-0.26540986]\n",
      "810 Cost: 0.009888991 W: [1.1153584] b: [-0.26223692]\n",
      "820 Cost: 0.009653953 W: [1.1139792] b: [-0.2591019]\n",
      "830 Cost: 0.009424518 W: [1.1126167] b: [-0.2560044]\n",
      "840 Cost: 0.009200523 W: [1.1112704] b: [-0.2529439]\n",
      "850 Cost: 0.008981849 W: [1.1099402] b: [-0.24991998]\n",
      "860 Cost: 0.008768385 W: [1.1086258] b: [-0.24693222]\n",
      "870 Cost: 0.008559995 W: [1.1073272] b: [-0.24398015]\n",
      "880 Cost: 0.008356547 W: [1.1060442] b: [-0.2410634]\n",
      "890 Cost: 0.008157934 W: [1.1047764] b: [-0.2381815]\n",
      "900 Cost: 0.007964038 W: [1.1035239] b: [-0.2353341]\n",
      "910 Cost: 0.007774755 W: [1.1022861] b: [-0.2325207]\n",
      "920 Cost: 0.007589988 W: [1.1010634] b: [-0.22974093]\n",
      "930 Cost: 0.0074095954 W: [1.0998552] b: [-0.22699441]\n",
      "940 Cost: 0.0072334833 W: [1.0986614] b: [-0.22428071]\n",
      "950 Cost: 0.0070615723 W: [1.097482] b: [-0.22159947]\n",
      "960 Cost: 0.0068937386 W: [1.0963166] b: [-0.21895027]\n",
      "970 Cost: 0.006729904 W: [1.0951651] b: [-0.21633276]\n",
      "980 Cost: 0.0065699555 W: [1.0940275] b: [-0.21374653]\n",
      "990 Cost: 0.0064138086 W: [1.0929034] b: [-0.21119122]\n",
      "1000 Cost: 0.0062613725 W: [1.0917927] b: [-0.20866647]\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5bad68eb41b8c41c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
